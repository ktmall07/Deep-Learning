{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgHSWrC8A8i-"
      },
      "source": [
        "<a \n",
        "href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab6.ipynb\"\n",
        "  target=\"_parent\">\n",
        "  <img\n",
        "    src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
        "    alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cksgAH12XRjV"
      },
      "source": [
        "# Lab 6: Sequence-to-sequence models\n",
        "\n",
        "### Description:\n",
        "For this lab, you will code up the [char-rnn model of Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). This is a recurrent neural network that is trained probabilistically on sequences of characters, and that can then be used to sample new sequences that are like the original.\n",
        "\n",
        "This lab will help you develop several new skills, as well as understand some best practices needed for building large models. In addition, we'll be able to create networks that generate neat text!\n",
        "\n",
        "### Deliverable:\n",
        "- Fill in the code for the RNN (using PyTorch's built-in GRU).\n",
        "- Fill in the training loop\n",
        "- Fill in the evaluation loop. In this loop, rather than using a validation set, you will sample text from the RNN.\n",
        "- Implement your own GRU cell.\n",
        "- Train your RNN on a new domain of text (Star Wars, political speeches, etc. - have fun!)\n",
        "\n",
        "### Grading Standards:\n",
        "- 20% Implementation the RNN\n",
        "- 20% Implementation training loop\n",
        "- 20% Implementation of evaluation loop\n",
        "- 20% Implementation of your own GRU cell\n",
        "- 20% Training of your RNN on a domain of your choice\n",
        "\n",
        "### Tips:\n",
        "- Read through all the helper functions, run them, and make sure you understand what they are doing\n",
        "- At each stage, ask yourself: What should the dimensions of this tensor be? Should its data type be float or int? (int is called `long` in PyTorch)\n",
        "- Don't apply a softmax inside the RNN if you are using an nn.CrossEntropyLoss (this module already applies a softmax to its input).\n",
        "\n",
        "### Example Output:\n",
        "An example of my final samples are shown below (more detail in the\n",
        "final section of this writeup), after 150 passes through the data.\n",
        "Please generate about 15 samples for each dataset.\n",
        "\n",
        "<code>\n",
        "And ifte thin forgision forward thene over up to a fear not your\n",
        "And freitions, which is great God. Behold these are the loss sub\n",
        "And ache with the Lord hath bloes, which was done to the holy Gr\n",
        "And appeicis arm vinimonahites strong in name, to doth piseling \n",
        "And miniquithers these words, he commanded order not; neither sa\n",
        "And min for many would happine even to the earth, to said unto m\n",
        "And mie first be traditions? Behold, you, because it was a sound\n",
        "And from tike ended the Lamanites had administered, and I say bi\n",
        "</code>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2i_QpSsWG4c"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 0: Readings, data loading, and high level training\n",
        "\n",
        "---\n",
        "\n",
        "There is a tutorial here that will help build out scaffolding code, and get an understanding of using sequences in pytorch.\n",
        "\n",
        "* Read the following\n",
        "\n",
        "> * [Pytorch sequence-to-sequence tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) (Take note that you will not be implementing the encoder part of this tutorial.)\n",
        "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7bdZWxvJrsx",
        "outputId": "6b40eb15-fa1f-4ddb-e5d9-cf714b06fae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-13 08:39:54--  https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz\n",
            "Resolving piazza.com (piazza.com)... 3.221.126.233, 54.156.235.193, 18.214.211.171, ...\n",
            "Connecting to piazza.com (piazza.com)|3.221.126.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-uploads.piazza.com/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz [following]\n",
            "--2022-02-13 08:39:55--  https://cdn-uploads.piazza.com/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz\n",
            "Resolving cdn-uploads.piazza.com (cdn-uploads.piazza.com)... 13.249.137.78, 13.249.137.97, 13.249.137.61, ...\n",
            "Connecting to cdn-uploads.piazza.com (cdn-uploads.piazza.com)|13.249.137.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1533290 (1.5M) [application/x-gzip]\n",
            "Saving to: ‘./text_files.tar.gz’\n",
            "\n",
            "./text_files.tar.gz 100%[===================>]   1.46M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-02-13 08:39:55 (25.5 MB/s) - ‘./text_files.tar.gz’ saved [1533290/1533290]\n",
            "\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.3.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "file_len = 78277\n"
          ]
        }
      ],
      "source": [
        "! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz' \n",
        "! tar -xzf text_files.tar.gz\n",
        "! pip install unidecode\n",
        "! pip install torch\n",
        "\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        " \n",
        "import pdb\n",
        " \n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "file = unidecode.unidecode(open('/content/Star Wars Episode IV.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxBeKeNjJ0NQ",
        "outputId": "d89e98ed-38b3-4028-ca4c-a8f4254d12aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "of this battle station.\"\n",
            "\"286\" \"TAGGE\" \"And what of the Rebellion?  If the Rebels have obtained a complete technical readout of this station, it is possible, however unlikely, that they might find a we\n"
          ]
        }
      ],
      "source": [
        "chunk_len = 200\n",
        " \n",
        "def random_chunk():\n",
        "  start_index = random.randint(0, file_len - chunk_len)\n",
        "  end_index = start_index + chunk_len + 1\n",
        "  return file[start_index:end_index]\n",
        "  \n",
        "print(random_chunk())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On0_WitWJ99e",
        "outputId": "d54dbf49-7936-45df-d76c-77fa393127b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()\n",
        "  for c in range(len(string)):\n",
        "      tensor[c] = all_characters.index(string[c])\n",
        "  return tensor\n",
        "\n",
        "print(char_tensor('abcDEF'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYJPTLcaYmfI"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: Creating your own GRU cell \n",
        "\n",
        "**(Come back to this later - its defined here so that the GRU will be defined before it is used)**\n",
        "\n",
        "---\n",
        "\n",
        "The cell that you used in Part 1 was a pre-defined Pytorch layer. Now, write your own GRU class using the same parameters as the built-in Pytorch class does.\n",
        "\n",
        "Please try not to look at the GRU cell definition. The answer is right there in the code, and in theory, you could just cut-and-paste it. This bit is on your honor!\n",
        "\n",
        "**TODO:**\n",
        "* Create a custom GRU cell\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "aavAv50ZKQ-F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers):\n",
        "    super(GRU, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.gru_cells = nn.ModuleList([])\n",
        "\n",
        "    for l in range(self.num_layers):\n",
        "      if l == 0:\n",
        "        gru_size = self.input_size\n",
        "      else:\n",
        "        gru_size = self.hidden_size\n",
        "      self.gru_cells.append(GRUCell(gru_size, hidden_size))\n",
        "  \n",
        "  def forward(self, inputs, hidden):\n",
        "    outputs, hiddens = self.gru_cells[0](inputs, hidden[0:1])\n",
        "\n",
        "    for l in range(1, self.num_layers):\n",
        "      outputs, hidden_layer = self.gru_cells[l](outputs, hidden[l:l+1])\n",
        "      hiddens = torch.cat((hiddens, hidden_layer), dim=0)\n",
        "\n",
        "    return outputs, hiddens  \n",
        "\n",
        "class GRUCell(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(GRUCell, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    self.sigmo = nn.Sigmoid()\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.W_r = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.W_z = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.W = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    \n",
        "  def forward(self, input, prev_hidden):\n",
        "    z_t = self.sigmo(self.W_z(torch.cat((input, prev_hidden), dim=2)))\n",
        "    r_t = self.sigmo(self.W_r(torch.cat((input, prev_hidden), dim=2)))\n",
        "    \n",
        "    h_t = self.tanh(self.W(torch.cat((torch.mul(r_t, prev_hidden), input), dim=2)))\n",
        "    h = torch.mul((1 - z_t), prev_hidden) + torch.mul(z_t, h_t)\n",
        "    \n",
        "    output = h\n",
        "    hidden = h\n",
        "    return output, h\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtXdX-B_WiAY"
      },
      "source": [
        "---\n",
        "\n",
        "##  Part 1: Building a sequence to sequence model\n",
        "\n",
        "---\n",
        "\n",
        "Great! We have the data in a useable form. We can switch out which text file we are reading from, and trying to simulate.\n",
        "\n",
        "We now want to build out an RNN model, in this section, we will use all built in Pytorch pieces when building our RNN class.\n",
        "\n",
        "\n",
        "**TODO:**\n",
        "* Create an RNN class that extends from nn.Module.\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "d6tNdEnzWj5F"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "    super(RNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    \n",
        "    # more stuff here...\n",
        "    self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
        "    self.gru = GRU(self.hidden_size, self.hidden_size, self.n_layers)\n",
        "    self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    \n",
        "\n",
        "  def forward(self, input_char, hidden_state):\n",
        "    # by reviewing the documentation, construct a forward function that properly uses the output\n",
        "    # of the GRU\n",
        "\n",
        "    # stuff here\n",
        "    embedded = self.embedding(input_char).view(1, 1, -1)\n",
        "    output, hidden = self.gru(embedded, hidden_state)\n",
        "    output = self.relu(self.out(output))\n",
        "\n",
        "    return output, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(self.n_layers, 1, self.hidden_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "hrhXghEPKD-5"
      },
      "outputs": [],
      "source": [
        "def random_training_set():    \n",
        "  chunk = random_chunk()\n",
        "  # print(chunk)\n",
        "  inp = char_tensor(chunk[:-1])\n",
        "  target = char_tensor(chunk[1:])\n",
        "  return inp, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpiGObbBX0Mr"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "We now want to be able to train our network, and sample text after training.\n",
        "\n",
        "This function outlines how training a sequence style network goes. \n",
        "\n",
        "**TODO:**\n",
        "* Fill in the pieces.\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "2ALC3Pf8Kbsi"
      },
      "outputs": [],
      "source": [
        "# NOTE: decoder_optimizer, decoder, and criterion will be defined below as global variables\n",
        "def train(inp, target):\n",
        "  ## initialize hidden layers, set up gradient and loss \n",
        "    # your code here\n",
        "  ## /\n",
        "\n",
        "  decoder_optimizer.zero_grad()\n",
        "  hidden = decoder.init_hidden()\n",
        "  loss = 0\n",
        "\n",
        "  for c in range(chunk_len):\n",
        "    c_decoded, hidden = decoder(inp[c], hidden)\n",
        "    loss += criterion(c_decoded.squeeze(0), target[c].unsqueeze(0))\n",
        "  \n",
        "  loss.backward()\n",
        "  decoder_optimizer.step()\n",
        "  loss_score = loss.item() / chunk_len\n",
        "\n",
        "  return loss_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN06NUu3YRlz"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 3: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "You can at this time, if you choose, also write out your train loop boilerplate that samples random sequences and trains your RNN. This will be helpful to have working before writing your own GRU class.\n",
        "\n",
        "If you are finished training, or during training, and you want to sample from the network you may consider using the following function. If your RNN model is instantiated as `decoder`then this will probabilistically sample a sequence of length `predict_len`\n",
        "\n",
        "**TODO:**\n",
        "* Fill out the evaluate function to generate text frome a primed string\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "B-bp-OZ1KjNh"
      },
      "outputs": [],
      "source": [
        "def sample_outputs(output, temperature):\n",
        "    \"\"\"Takes in a vector of unnormalized probability weights and samples a character from the distribution\"\"\"\n",
        "    return torch.multinomial(torch.exp(output / temperature), 1)\n",
        "\n",
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "  ## initialize hidden state, initialize other useful variables\n",
        "    # your code here\n",
        "  ## /\n",
        "  hidden = decoder.init_hidden()\n",
        "  predicted = prime_str\n",
        "  prime_characters = char_tensor(prime_str)\n",
        "\n",
        "  for i in range(len(prime_str) - 1):\n",
        "    _, hidden = decoder(prime_characters[i], hidden)\n",
        "  \n",
        "  eval_character = prime_characters[-1]\n",
        "\n",
        "  for j in range(predict_len):\n",
        "    out, hidden = decoder(eval_character, hidden)\n",
        "    sample = sample_outputs(out.data.view(-1), temperature)\n",
        "\n",
        "    choice = all_characters[sample]\n",
        "    eval_character = char_tensor(choice)\n",
        "    predicted += choice\n",
        "\n",
        "    # pdb.set_trace()\n",
        "  \n",
        "  return predicted\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du4AGA8PcFEW"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: (Create a GRU cell, requirements above)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFS2bpHSZEU6"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Part 5: Run it and generate some text!\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**TODO:** \n",
        "* Create some cool output\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Assuming everything has gone well, you should be able to run the main function in the scaffold code, using either your custom GRU cell or the built in layer, and see output something like this. I trained on the “lotr.txt” dataset, using chunk_length=200, hidden_size=100 for 2000 epochs. These are the results, along with the prime string:\n",
        "\n",
        "---\n",
        "\n",
        " G:\n",
        " \n",
        " Gandalf was decrond. \n",
        "'All have lord you. Forward the road at least walk this is stuff, and \n",
        "went to the long grey housel-winding and kindled side was a sleep pleasuring, I do long \n",
        "row hrough. In  \n",
        "\n",
        " lo:\n",
        " \n",
        " lost death it. \n",
        "'The last of the gatherings and take you,' said Aragorn, shining out of the Gate. \n",
        "'Yes, as you there were remembaused to seen their pass, when? What \n",
        "said here, such seven an the sear \n",
        "\n",
        " lo:\n",
        " \n",
        " low, and frod to keepn \n",
        "Came of their most. But here priced doubtless to an Sam up is \n",
        "masters; he left hor as they are looked. And he could now the long to stout in the right fro horseless of \n",
        "the like \n",
        "\n",
        " I:\n",
        " \n",
        " I had been the \n",
        "in his eyes with the perushed to lest, if then only the ring and the legended \n",
        "of the less of the long they which as the \n",
        "enders of Orcovered and smood, and the p \n",
        "\n",
        " I:\n",
        " \n",
        " I they were not the lord of the hoomes. \n",
        "Home already well from the Elves. And he sat strength, and we \n",
        "housed out of the good of the days to the mountains from his perith. \n",
        "\n",
        "'Yess! Where though as if  \n",
        "\n",
        " Th:\n",
        " \n",
        " There yarden \n",
        "you would guard the hoor might. Far and then may was \n",
        "croties, too began to see the drumbred many line \n",
        "and was then hoard walk and they heart, and the chair of the \n",
        "Ents of way, might was \n",
        "\n",
        " G:\n",
        " \n",
        " Gandalf \n",
        "been lat of less the round of the stump; both and seemed to the trees and perished they \n",
        "lay are speered the less; and the wind the steep and have to she \n",
        "precious. There was in the oonly went \n",
        "\n",
        " wh:\n",
        " \n",
        " which went out of the door. \n",
        "Hull the King and of the The days of his brodo \n",
        "stumbler of the windard was a thing there, then it been shining langing \n",
        "to him poor land. They hands; though they seemed ou \n",
        "\n",
        " ra:\n",
        " \n",
        " rather,' have all the least deather \n",
        "down of the truven beginning to the house of sunk. \n",
        "'Nark shorts of the Eyes of the Gate your great nothing as Eret. \n",
        "'I wander trust horn, and there were not, it  \n",
        "\n",
        " I:\n",
        " \n",
        " I can have no mind \n",
        "together! Where don't may had one may little blung \n",
        "terrible to tales. And turn and Gandalf shall be not to as only the Cattring \n",
        "not stopped great the out them forms. On they she lo \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "-nXFeCmdKodw"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "n_epochs = 5000\n",
        "print_every = 200\n",
        "plot_every = 10\n",
        "hidden_size = 200\n",
        "n_layers = 2\n",
        "lr = 0.001\n",
        " \n",
        "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        " \n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKfozqw-6eqb",
        "outputId": "3e0e3a7e-0851-421a-b476-eb855fe22acf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[111.60166549682617 (200 4%) 2.4159]\n",
            "Whe the us, and *abours to saritde the winked Zramy themres andt on Xlentor softhe int lome wand ot, a \n",
            "\n",
            "[220.24724102020264 (400 8%) 2.1502]\n",
            "Whsund reping ay ay the roth the care some dides, she one lyon to ow and \feren, and or terene ase the  \n",
            "\n",
            "[327.6690442562103 (600 12%) 1.8674]\n",
            "Whing a down was and stall the you suclledy or of shook not suspung the looked at minse, and \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "[435.39996695518494 (800 16%) 1.9827]\n",
            "Whed, would were, camled gonney ony agaar move ahove other undell the word his word the down sighFrost \n",
            "\n",
            "[556.5108437538147 (1000 20%) 1.7561]\n",
            "Whing if that was cag!' saiked who have make on thim, and not should got on then his shive his truits  \n",
            "\n",
            "[665.9958119392395 (1200 24%) 1.6033]\n",
            "Whien this what &ro`e, his \n",
            "look, Lut and all the reast too a father \n",
            "had shall then the swars \n",
            "hon(r  \n",
            "\n",
            "[774.2663886547089 (1400 28%) 1.6684]\n",
            "Wh \n",
            "men than ever to the rest still gainly dark and still came acried all from \n",
            "grew and rearor his fe \n",
            "\n",
            "[881.9017586708069 (1600 32%) 1.7777]\n",
            "Whelf in feor turned \n",
            "to they white oth rent here with when \n",
            "have dangs it so me handin\f to the dare w \n",
            "\n",
            "[989.352117061615 (1800 36%) 2.2092]\n",
            "Wh words himselove he risters of \n",
            "the peepsing the aragorn \n",
            "from his going awong \n",
            "see shoulder on the  \n",
            "\n",
            "[1098.1440901756287 (2000 40%) 1.5637]\n",
            "When thought Bould had one litter to he concer for, and in a long of the water, mall ? and sto hidus o \n",
            "\n",
            "[1205.8547158241272 (2200 44%) 1.6670]\n",
            "Whorcome any, and not on the stood in the sat is to face, knowger the were at a darknessed and all the \n",
            "\n",
            "[1313.3706483840942 (2400 48%) 1.8601]\n",
            "Whlegs a9 \n",
            "riden which rider and length did were gateland of them at is a trew the gate of the \n",
            "had \n",
            "o \n",
            "\n",
            "[1423.044133901596 (2600 52%) 1.5122]\n",
            "Whing to other \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "clowed and in some \n",
            "shall will to get having on still might came, and shellyW can  \n",
            "\n",
            "[1532.361756324768 (2800 56%) 1.7245]\n",
            "Who have softer the have heart come out after many handsq}ick, and the endure and lad slowling with la \n",
            "\n",
            "[1640.96741604805 (3000 60%) 1.4263]\n",
            "Where \n",
            "aggy leanion to figging to the dain0ly partway, and )olders servant, all ever the Wood, an \n",
            "\n",
            "[1748.4977858066559 (3200 64%) 1.5176]\n",
            "What yeer find could earth that he said\n",
            "easely the \n",
            "(amon,' said The larger, and that a looking and hi \n",
            "\n",
            "[1855.0379905700684 (3400 68%) 1.5169]\n",
            "Where he could than the fire theared to accome, as if xeckant age was \n",
            "store the stay 3 \n",
            "\n",
            "Tower in the \n",
            "\n",
            "[1963.4602589607239 (3600 72%) 1.1923]\n",
            "When my stast them in the rest, and all their says of the skirts and a five \n",
            "were away \n",
            "and it south t \n",
            "\n",
            "[2071.1892330646515 (3800 76%) 1.7769]\n",
            "Whered to his dead to stood any, }ut of he had not to pursuing that they keep in an outhars, and he ca \n",
            "\n",
            "[2179.309732913971 (4000 80%) 1.8272]\n",
            "What almost to smowly the first at himself, and have he last have make, and that had the \n",
            "Wover on the \n",
            "\n",
            "[2288.1742317676544 (4200 84%) 1.5460]\n",
            "Where your need him by the should \n",
            "trawl in *an came shreked 1 \n",
            "\n",
            "White since he like the covered the v \n",
            "\n",
            "[2397.605344057083 (4400 88%) 1.2508]\n",
            "Wh white said allows, \n",
            "auil5 \n",
            "and late all all  \n",
            "\n",
            "[2505.3360579013824 (4600 92%) 1.3541]\n",
            "Wh a staren it \n",
            "more bent the little and an his speak than a pany, for still still \n",
            "not and helm ware  \n",
            "\n",
            "[2611.8758804798126 (4800 96%) 1.5054]\n",
            "Wheless!' he said to gone bright the lands of the \n",
            "\n",
            "Three \n",
            "speak \n",
            "into the \n",
            "barren beyond it in the mi \n",
            "\n",
            "[2719.2207639217377 (5000 100%) 1.5566]\n",
            "Wh \n",
            "their single of making on the \n",
            "hold, came that \n",
            "while' said the dark wound it \n",
            "not yet brows crack \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# n_epochs = 2000\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  loss_ = train(*random_training_set())       \n",
        "  loss_avg += loss_\n",
        "\n",
        "  if epoch % print_every == 0:\n",
        "      print('[%s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
        "      print(evaluate('Wh', 100), '\\n')\n",
        "\n",
        "  if epoch % plot_every == 0:\n",
        "      all_losses.append(loss_avg / plot_every)\n",
        "      loss_avg = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee0so6aKJ5L8",
        "outputId": "b3c0ae81-11af-44ea-9115-35b649a73fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " he\n",
            " he were \n",
            "step and look and pace glad tider on \n",
            "come to \n",
            "try to you wise, and \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "were goes that watcher stew a huddle for no at last afraithless on \n",
            "and {oung on fance, but drove the companished li \n",
            "\n",
            " ca\n",
            " carry and come to me stars and courself, and when you \n",
            "did not all the forest grace in the grass of their deepening of the sgones won't some at him was slow and died days of the \n",
            "would not the fail}y of \n",
            "\n",
            " Th\n",
            " Thjoden \n",
            "that is \n",
            "more men ceon?' \n",
            "\n",
            "'That's the trees are \n",
            "in the passed, not lookly so Thjoden to the doorKhere wind one better to mmuch many closed knows of my charp had strange \n",
            "came, do you knows pl \n",
            "\n",
            " ra\n",
            " raised down to get down down, 'the \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "now to shall be a prumbly to here, and \n",
            "trust at the =road even \n",
            "as the days, when the in \n",
            "the \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "more his \n",
            "way and now what was nearly him to do to \n",
            "covers \n",
            "\n",
            " G\n",
            " Gollum \n",
            "so the lights, but if clad and \n",
            "your part \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "now more on the \n",
            "end of when the traith or \n",
            "anly when they said, which things to the \n",
            "started, alos on it \n",
            "they stood down a more that were lenge  \n",
            "\n",
            " I \n",
            " I one had they \n",
            "could teed earth and made a silendi?' said Brandy \n",
            "down to the \n",
            "eorn the \n",
            "horn were neartning, and it was great wonder land passed a mank of the road to \n",
            "\tight, and with to find for it o \n",
            "\n",
            " ra\n",
            " ran meciath, and trumbling passed_ and \n",
            "nace to the trees, and there was for my very long mrand that \n",
            "the \n",
            "One of the winging tall of trees came to the way, and they late of @obba[: Two may \n",
            "stars \n",
            "to t \n",
            "\n",
            " G\n",
            " Gandalf went to that it was much pany wising \n",
            "the coming who \n",
            "chair \n",
            "\n",
            "filled blowd above, and we had it is pale came deep something in from the and look never fell to the poor to mind, \n",
            "and trath us th \n",
            "\n",
            " wh\n",
            " when stand the }endoned himver had do one to his left a while go it again, then \n",
            "had say, and he prone and not singered, so more \n",
            "becausted on to the only at the song from on him, for so my must me!' he \n",
            "\n",
            " I \n",
            " I know that the hobbits a fair for soon to must keep \n",
            "some came a word for the \n",
            "eastion hurrier, who do you comeZfing, and show it the northern \n",
            "strange tall, lord and clafgered under their part, but th \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "#   all_characters.index(string[c])\n",
        "  print(evaluate(start_strings[start], 200), '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJhgDc2IauPE"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 6: Generate output on a different dataset\n",
        "\n",
        "---\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* Choose a textual dataset. Here are some [text datasets](https://www.kaggle.com/datasets?tags=14104-text+data%2C13205-text+mining) from Kaggle \n",
        "\n",
        "* Generate some decent looking results and evaluate your model's performance (say what it did well / not so well)\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training on the Script from Star Wars Episode IV: A New Hope\n",
        "import time\n",
        "n_epochs = 5000\n",
        "print_every = 200\n",
        "plot_every = 10\n",
        "hidden_size = 200\n",
        "n_layers = 2\n",
        "lr = 0.001\n",
        " \n",
        "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        " \n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  loss_ = train(*random_training_set())       \n",
        "  loss_avg += loss_\n",
        "\n",
        "  if epoch % print_every == 0:\n",
        "      print('[%s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
        "      print(evaluate('Wh', 100), '\\n')\n",
        "\n",
        "  if epoch % plot_every == 0:\n",
        "      all_losses.append(loss_avg / plot_every)\n",
        "      loss_avg = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxW8qG5fO1Cx",
        "outputId": "8df8fbcb-c13f-4684-f79e-6b032c76641a"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[112.06821966171265 (200 4%) 2.3851]\n",
            "Whc ell =ePeodert Re hgo lofer.\"\n",
            "\"222\" \"cUent.\"\n",
            "\"461\" \"Pdene hen, hepe sugis seiy\ftou.\"\n",
            "\"12\" \"j\u000bn\ft Fe \n",
            "\n",
            "[223.20258116722107 (400 8%) 2.4407]\n",
            "Where tus st?  tel trout in dnoA\"\n",
            "\"27\" \"I>E\" \"Moand this in.\"\n",
            "  HeloU ree plond denthe \n",
            "\n",
            "[357.6770758628845 (600 12%) 2.0028]\n",
            "WhjMD sightes.  ! Jipe.\"\n",
            "'s c8ire is the king he well!   on't I droing 'isse stri puster.\"\n",
            "\"8 \n",
            "\n",
            "[501.9059684276581 (800 16%) 1.9428]\n",
            "Whe giction the could the do(+You going in ;ere...  I stO-I\n",
            "\"3J\" \"OA\\Rs I seed We'd m-The to Qoing in  \n",
            "\n",
            "[643.82537150383 (1000 20%) 1.7886]\n",
            "Wh the cleSt 0>[en here...\"\n",
            "\"565\" \"HAN\" \"He st8ick it!  Kid!\"\n",
            "\"89\" \"THREEPIO\" \"I for sir.\"\n",
            "\"261\" \"yATh \n",
            "\n",
            "[786.3125822544098 (1200 24%) 1.5581]\n",
            "Wh\" \"zeter he c^rest it 1332\" \"THREEPIO\" \"I c6Mriden trince.  I'll I's luite or Bust You on't kid he l \n",
            "\n",
            "[929.8766872882843 (1400 28%) 1.7641]\n",
            "orse the to sTe}vount.\"\n",
            "\"850\" \"THREEPIO\" \"The 1:4\" \"CO%ceDetrou  \n",
            "\n",
            "[1072.8273215293884 (1600 32%) 1.6606]\n",
            "Whole st^ng here.\"\n",
            "\"518\" \"THREEPIO\" \"Are on the rebely into still to the Force to get it.\"\n",
            "\"278\" \"THRE \n",
            "\n",
            "[1215.2124178409576 (1800 36%) 1.6247]\n",
            "Where copdinneCUh, sir, ?U0\" \"Ovinge to be a decopsert.  This to find the locatiop in po?\"\n",
            "\"840\" \"HAN\" \n",
            "\n",
            "[1356.2061009407043 (2000 40%) 1.2928]\n",
            "Where is a shore the main.\"\n",
            "\"263\" \"<EVE\" \"He ship as him.  the like the is is your ships.\"\n",
            "\"926\" \"HAN\" \n",
            "\n",
            "[1497.114930152893 (2200 44%) 1.3998]\n",
            "Wh tell to have mover on.  Ten them computer.  This is I think here!\"\n",
            "\"900\" \"qO`t in the carn.  The Fo \n",
            "\n",
            "[1639.2906787395477 (2400 48%) 1.4637]\n",
            "What work this stations of here.\"\n",
            "\"271\" \"OJOFIm mark of there are system.\"\n",
            "\"344\" \"REWAld %en the somet \n",
            "\n",
            "[1782.8470723628998 (2600 52%) 1.1795]\n",
            "Wh, I can't have a droid enough to the detention is putine.\"\n",
            "\"877\" \";OTAN\" \"looking with you.\"\n",
            "\"231\" \" \n",
            "\n",
            "[1923.9061453342438 (2800 56%) 0.9924]\n",
            "What lost something?\"\n",
            "\"263\" \"xKEqE\" \"The 3e`&\" \"You don't be in guves ally...  I'm leak on me you conc \n",
            "\n",
            "[2068.3216381073 (3000 60%) 1.3566]\n",
            "Wh you get I've got over than me my dier in the station.\"\n",
            "\"902\" \"RE\n",
            "\"MO\" \"chate I thought he may main  \n",
            "\n",
            "[2211.117097377777 (3200 64%) 1.1638]\n",
            "Wh he means and *adbel the may.  He had you get out your controls.\"\n",
            "\"399\" \"HAN\" \"It aren't it.  You'll \n",
            "\n",
            "[2350.4797265529633 (3400 68%) 1.1210]\n",
            "What what happened teen were bun.  It's something you're stick might find your system.  There you goin \n",
            "\n",
            "[2492.5506885051727 (3600 72%) 1.1728]\n",
            "What we're doesn't believe to the ort down sure this princess.  2ut that would every port around.  If  \n",
            "\n",
            "[2632.2884261608124 (3800 76%) 1.1326]\n",
            "What's the =arse, I man it no about the target in the name fool... at what he?  He's heading me, if yo \n",
            "\n",
            "[2766.728625535965 (4000 80%) 1.2291]\n",
            "What you'll me recording.\"\n",
            "\"544\" \"-HAN\" \"It's a spoit of speed.  I was something good as it is ideas.\" \n",
            "\n",
            "[2901.80859875679 (4200 84%) 0.9851]\n",
            "Who is she may not even but the warge possay than \"I can do about it half you with you the down sim.   \n",
            "\n",
            "[3035.5713658332825 (4400 88%) 1.0681]\n",
            "Where you going to the damage star we are more than take the tractor have commander... these gone to t \n",
            "\n",
            "[3171.3634645938873 (4600 92%) 0.6858]\n",
            "et's get be oution. \"\n",
            "\"82\" \"QOIAN\" \"Red Ten as mather was a f \n",
            "\n",
            "[3308.4688918590546 (4800 96%) 0.8611]\n",
            "Wh asle!  Okay.  I can make us to dest malfry little for you, with that the looks like you coming in m \n",
            "\n",
            "[3444.1610095500946 (5000 100%) 0.7601]\n",
            "What?\"\n",
            "\"659\" \"\n",
            "\"TFICER\" \"we're coming back...\"\n",
            "\"955\" \"\\Oqun their all throttle.\"\n",
            "\"969\" \"81cE;A\" \"If th \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "#   all_characters.index(string[c])\n",
        "  print(evaluate(start_strings[start], 200), '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXHjq--aYPNa",
        "outputId": "a105c902-e53b-4f13-c820-83db998e2fb5"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " he\n",
            " help.  I don't have to contrugh more for sad so...\"\n",
            "\"204\" \"THREEPIO\" \"I want you to make they must also all the planet good overative starships.  Flast the end here.\"\n",
            "\"555\" \"HAN\" \"Not an eyes there...\"\n",
            " \n",
            "\n",
            " he\n",
            " help move?\"\n",
            "\"359\" \"fEATARKIN\" \"This is some space still, sir.  I can't see and were been short-citching to let a starships?  What are you ain't amaty fire the galayong to find your father?\"\n",
            "\"450\" \">AN\"  \n",
            "\n",
            " ca\n",
            " can do bot one of this technolow that they idenctionaly way or against the money only one-man mantoor your run.\"\n",
            "\"994\" \"REm one-man fire yourself of anything... that the battle station.\"\n",
            "\"426\" \"HAN\" \"Ch \n",
            "\n",
            " lo\n",
            " lost standing by.\"\n",
            "\"547\" \"HAN\" \"It's power of the plans to that way!  Memnet this, but do you think you let you say sir, I think she would I need you the door.  I wonder of there was a whole droids.  It \n",
            "\n",
            " ca\n",
            " can't get out of here enough.  In quite for sure, sir, no little from the plans that.\"\n",
            "\"955\" \"RE+\" \"It's a lottached to talking.\"\n",
            "\"863\" \"REven if I can't make an eever propy.\"\n",
            "\"157\" \"HAN\" \"It's time so  \n",
            "\n",
            " ra\n",
            " ratant to learn the choose.\"\n",
            "\"990\" \"RE6\" \"Uncle Owen...\"\n",
            "\"66\" \")AN\" \"It mas the big trust the matter.  |ourse, \\rid.  If ,orms let is.\"\n",
            "\"269\" \"EATHINT NINEN\" \"Hold time of the most.  (ourself in the All \n",
            "\n",
            " G\n",
            " Greedo to learn sometimes.\"\n",
            "\"139\" \"OvINE\" \"Red Three standing by.\"\n",
            "\"944\" \"REF Of the to fire power... where are you talking about.  If a sImmenging.  They've omay or on the plans marked for syster!  vo \n",
            "\n",
            " ra\n",
            " range.\"\n",
            "\"54\" \"CONTARKIN\" \"Come on!  >urry!\"\n",
            "\"699\" \"HAN\" \"ust this way, #o standing by.\"\n",
            "\"857\" \"REBE\" \"I think I see what as malfunctioning in I was going to let we sand >en I need your father.\"\n",
            "\"892\" \"R \n",
            "\n",
            " wh\n",
            " who she isn't control who is thousand.  He hadn't have your stations.\"\n",
            "un I can't soon watch your father.\"\n",
            "\"893\" \"|HIEF\" \"I told your hands, we can't make they suright smalfunctions?\"\n",
            "\"532\" \"H \n",
            "\n",
            " ra\n",
            " rats when you all right.  He's a \\et off, sir.  If you can do with me to let it sometimes on!\"\n",
            "\"513\" \"OFFICER\" \"I can't shake him.  I'm sorry.\"\n",
            "\"794\" \"HAN\" \"He's location anything.\"\n",
            "\"953\" \"RE*: Only tak \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because of the format of the text document: \"LineNumber\" \"Name\": Line\n",
        "I think my model had more trouble than with the Lord of the Rings text. There are not only numbers, but also symbols in the names and lines that were not there in the Lord of the Rings text, so it had a harder time making sense of them. However, it started to recognize where the symbols belonged through training, and generally put them in the right place after fully training. I think that this could have been fixed if I had extended the length of the passage taken in to around 2x the amount of characters used by the Lord of the Rings training. It was interesting to see the results even still. The model definitely picked up a lot of the most common phrases and words, like \"Force\", \"System\", \"ship\", \"Red Three\", and \"rebels\". If I had more time, I would train the model again with twice the amount of characters so it could take in more lines at a time.\n",
        "\n",
        "By the end, the model successfully created some lines that convincingly sound like they're out of a Star Wars movie! It even matched unique ways of speaking with the correct characters, like C3PO, Grand Moff Tarkin, and Han Solo. With more training, I'm sure that the model would do even better."
      ],
      "metadata": {
        "id": "HjnS71YJWUk9"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "lab6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}